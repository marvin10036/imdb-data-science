# Plano de Implementa√ß√£o: Modelo de Predi√ß√£o de Indica√ß√µes ao Oscar

## Objetivo

Desenvolver um modelo de Machine Learning para prever quais filmes ser√£o indicados ao Oscar de Melhor Filme em 2025, utilizando dados hist√≥ricos de 2000-2024.

## Contexto

O projeto j√° possui:

- ‚úÖ Banco de dados PostgreSQL estruturado com filmes de 1980-2025
- ‚úÖ Schema normalizado com tabelas de filmes, pessoas, g√™neros, pa√≠ses, box office, etc.
- ‚úÖ Dados do IMDb combinados com scores do Metacritic
- ‚úÖ View SQL `ml_training_dataset` preparada para exporta√ß√£o

## Fases do Projeto

### Fase 1: An√°lise Explorat√≥ria de Dados (EDA)

**Objetivo**: Entender profundamente os dados antes de treinar qualquer modelo.

#### 1.1 Setup do Ambiente

- Criar diret√≥rio `notebooks/` para an√°lise
- Configurar Jupyter Notebook
- Instalar bibliotecas necess√°rias (pandas, numpy, matplotlib, seaborn, scikit-learn, etc.)
- Criar conex√£o com banco PostgreSQL

#### 1.2 Extra√ß√£o de Dados

- Exportar view `ml_training_dataset` para CSV
- Carregar dados em Pandas DataFrame
- Criar backup dos dados brutos

#### 1.3 An√°lise Inicial

- **Dimens√µes do dataset**: Total de filmes, features, per√≠odo coberto
- **Balanceamento de classes**: Ratio indicados vs n√£o-indicados
- **Dados faltantes**: Identificar colunas com NULLs e percentuais
- **Tipos de dados**: Verificar se todas as features est√£o nos tipos corretos

#### 1.4 An√°lise Univariada

Para cada feature num√©rica:

- Estat√≠sticas descritivas (m√©dia, mediana, std, min, max)
- Distribui√ß√µes (histogramas)
- Identifica√ß√£o de outliers (boxplots)

#### 1.5 An√°lise Bivariada

- Correla√ß√£o entre features num√©ricas
- Compara√ß√£o de distribui√ß√µes: indicados vs n√£o-indicados
- Identificar features mais discriminativas

#### 1.6 An√°lise Temporal

- Distribui√ß√£o de filmes por ano
- Evolu√ß√£o de indica√ß√µes ao longo do tempo
- Sazonalidade (meses de lan√ßamento)

#### 1.7 An√°lise de Features Categ√≥ricas

- Consultar banco para dados de g√™neros, diretores, pa√≠ses
- Identificar g√™neros/pessoas mais frequentes entre indicados
- Preparar para one-hot encoding

---

### Fase 2: Feature Engineering

**Objetivo**: Criar novas features que melhorem o poder preditivo do modelo.

#### 2.1 Features Temporais

- M√™s de lan√ßamento (filmes de final de ano t√™m mais chances?)
- Dist√¢ncia at√© a cerim√¥nia do Oscar
- Diferen√ßa entre `release_year` e `oscar_ceremony_year`

#### 2.2 Features Derivadas Num√©ricas

- ROI (Return on Investment) - j√° existe na view
- Ratio `domestic_gross / worldwide_gross` (desempenho nos EUA)
- √çndice de efici√™ncia: `worldwide_gross / runtime_minutes`
- Normaliza√ß√£o de ratings (z-score por ano)
- Ranking de bilheteria dentro do ano

#### 2.3 Features de Hist√≥rico (Prest√≠gio)

- N√∫mero de indica√ß√µes/vit√≥rias anteriores do diretor
- N√∫mero de indica√ß√µes/vit√≥rias anteriores dos atores principais
- Est√∫dio/produtora com hist√≥rico de Oscar

#### 2.4 Features Categ√≥ricas Expandidas

- One-hot encoding para top N g√™neros
- One-hot encoding para top N diretores
- One-hot encoding para pa√≠ses de produ√ß√£o
- Features booleanas: "Drama?", "Thriller?", "Biography?" etc.

#### 2.5 Features de Texto (Opcional/Avan√ßado)

- TF-IDF da sinopse
- An√°lise de sentimento da sinopse
- Presen√ßa de palavras-chave ("based on true story", "war", etc.)

#### 2.6 Cria√ß√£o de Dataset Final

- Consolidar todas as features em um √∫nico DataFrame
- Documentar significado de cada coluna
- Salvar vers√£o processada

---

### Fase 3: Prepara√ß√£o de Dados para ML

**Objetivo**: Preparar dados no formato adequado para treinamento.

#### 3.1 Tratamento de Valores Ausentes

- **Estrat√©gia 1**: Imputa√ß√£o com mediana/m√©dia (features num√©ricas)
- **Estrat√©gia 2**: Imputa√ß√£o com moda (features categ√≥ricas)
- **Estrat√©gia 3**: Criar flag "missing" como feature adicional
- Documentar decis√µes de imputa√ß√£o

#### 3.2 Tratamento de Outliers

- Identificar outliers extremos
- Decidir: remover, winsorizar ou manter?
- Aplicar transforma√ß√µes (log, sqrt) se necess√°rio

#### 3.3 Codifica√ß√£o de Vari√°veis Categ√≥ricas

- One-hot encoding para g√™neros, pa√≠ses, etc.
- Label encoding onde apropriado
- Garantir que categorias de treino/teste sejam consistentes

#### 3.4 Normaliza√ß√£o/Padroniza√ß√£o

- StandardScaler para features com distribui√ß√£o normal
- MinMaxScaler para features com limites claros
- RobustScaler para features com outliers
- Aplicar apenas ap√≥s split treino/teste (evitar data leakage)

#### 3.5 Split Temporal do Dataset

**CR√çTICO**: Respeitar temporalidade!

```
Treino:    2000-2019 (20 anos)
Valida√ß√£o: 2020-2022 (3 anos)
Teste:     2023-2024 (2 anos)
Predi√ß√£o:  2025 (futuro real)
```

N√£o usar `train_test_split` aleat√≥rio!

#### 3.6 Balanceamento de Classes

Testar estrat√©gias:

- **Baseline**: Dados desbalanceados + class_weight
- **Undersampling**: RandomUnderSampler
- **Oversampling**: SMOTE (Synthetic Minority Over-sampling)
- **Hybrid**: Combina√ß√£o de ambos

---

### Fase 4: Modelagem e Treinamento

**Objetivo**: Treinar e comparar diferentes modelos de ML.

#### 4.1 Baseline: Modelo Dummy

- `DummyClassifier` (estratified)
- Estabelecer performance m√≠nima aceit√°vel

#### 4.2 Modelos Lineares

- Logistic Regression
- Regulariza√ß√£o (L1, L2, ElasticNet)
- Interpreta√ß√£o de coeficientes

#### 4.3 Modelos Baseados em √Årvores

- Decision Tree (baseline)
- Random Forest (ensemble)
- Extra Trees

#### 4.4 Gradient Boosting

- XGBoost
- LightGBM
- CatBoost (bom para categ√≥ricas)

#### 4.5 Outros Algoritmos

- Support Vector Machines (SVM)
- K-Nearest Neighbors (KNN)
- Naive Bayes

#### 4.6 Tuning de Hiperpar√¢metros

- Grid Search ou Random Search
- Cross-validation temporal (TimeSeriesSplit adaptado)
- Otimizar para F1-Score ou AUC-ROC

#### 4.7 Ensemble de Modelos

- Voting Classifier
- Stacking
- Blending

---

### Fase 5: Avalia√ß√£o e Interpreta√ß√£o

**Objetivo**: Avaliar modelos e entender as predi√ß√µes.

#### 5.1 M√©tricas de Performance

Para dados desbalanceados, avaliar:

- **Precision**: Dos que prevemos como indicados, quantos realmente foram?
- **Recall**: Dos que foram indicados, quantos conseguimos prever?
- **F1-Score**: M√©dia harm√¥nica de precision e recall
- **AUC-ROC**: Capacidade de discrimina√ß√£o
- **Confusion Matrix**: An√°lise de erros (FP, FN)
- **PR Curve**: Precision-Recall curve

#### 5.2 Valida√ß√£o no Conjunto de Teste

- Aplicar melhor modelo em dados 2023-2024
- Comparar com indica√ß√µes reais conhecidas
- An√°lise de erros: quais filmes erramos e por qu√™?

#### 5.3 Feature Importance

- Identificar features mais importantes
- SHAP values (explicabilidade)
- Permutation importance
- Visualizar contribui√ß√µes

#### 5.4 An√°lise de Casos

- **True Positives**: Filmes corretamente preditos como indicados
- **False Positives**: Filmes que previmos mas n√£o foram indicados (por qu√™?)
- **False Negatives**: Filmes indicados que n√£o previmos (o que faltou?)
- **True Negatives**: Validar se s√£o realmente improv√°veis

#### 5.5 Calibra√ß√£o de Probabilidades

- Reliability diagram
- Calibra√ß√£o de Platt ou isot√¥nica
- Interpretar scores de probabilidade

---

### Fase 6: Predi√ß√£o para 2025

**Objetivo**: Gerar predi√ß√µes reais para filmes de 2025.

#### 6.1 Prepara√ß√£o de Dados 2025

- Filtrar filmes com `release_year = 2025`
- Verificar completude de features
- Aplicar mesmas transforma√ß√µes/normaliza√ß√µes

#### 6.2 Gera√ß√£o de Predi√ß√µes

- Aplicar modelo treinado
- Gerar probabilidades de indica√ß√£o
- Rankear filmes por probabilidade

#### 6.3 An√°lise de Resultados

- Top 10 filmes com maior probabilidade
- Top 20 para margem de seguran√ßa
- Identificar features que mais influenciaram

#### 6.4 Valida√ß√£o de Sanity

- Predi√ß√µes fazem sentido?
- Filmes conhecidos est√£o bem posicionados?
- H√° surpresas interessantes?

#### 6.5 Documenta√ß√£o de Predi√ß√µes

- Criar relat√≥rio com:
  - Top N filmes preditos
  - Probabilidades
  - Features mais importantes de cada filme
  - Justificativas do modelo

---

### Fase 7: Documenta√ß√£o e Pr√≥ximos Passos

**Objetivo**: Consolidar aprendizados e preparar para futuro.

#### 7.1 Documenta√ß√£o T√©cnica

- Notebook final limpo e comentado
- README do projeto
- Instru√ß√µes para reproduzir
- Requisitos e depend√™ncias

#### 7.2 Visualiza√ß√µes e Dashboard

- Criar visualiza√ß√µes das predi√ß√µes
- Dashboard interativo (Streamlit/Gradio?)
- Exportar para formatos compartilh√°veis

#### 7.3 Aprendizados e Limita√ß√µes

- O que funcionou bem?
- O que n√£o funcionou?
- Limita√ß√µes do modelo
- Vieses identificados

#### 7.4 Melhorias Futuras

- Coletar mais dados (streaming numbers, redes sociais)
- Incorporar dados de festivais (Cannes, Venice, TIFF)
- Adicionar categorias espec√≠ficas (Ator, Diretor, etc.)
- Modelo temporal sequencial (LSTM, Transformer)
- Atualizar modelo anualmente

---

## Cronograma Estimado

| Fase                   | Tempo Estimado | Status      |
| ---------------------- | -------------- | ----------- |
| 1. EDA                 | 2-3 sess√µes    | üîÑ Pr√≥xima  |
| 2. Feature Engineering | 2-3 sess√µes    | ‚è≥ Pendente |
| 3. Prepara√ß√£o de Dados | 1-2 sess√µes    | ‚è≥ Pendente |
| 4. Modelagem           | 3-4 sess√µes    | ‚è≥ Pendente |
| 5. Avalia√ß√£o           | 1-2 sess√µes    | ‚è≥ Pendente |
| 6. Predi√ß√£o 2025       | 1 sess√£o       | ‚è≥ Pendente |
| 7. Documenta√ß√£o        | 1 sess√£o       | ‚è≥ Pendente |

**Total**: ~11-18 sess√µes de trabalho

---

## Tecnologias e Bibliotecas

### Ambiente

- Python 3.8+
- Jupyter Notebook / JupyterLab
- PostgreSQL (j√° configurado)

### Bibliotecas Principais

```python
# Manipula√ß√£o de dados
pandas, numpy

# Visualiza√ß√£o
matplotlib, seaborn, plotly

# Conex√£o com banco
psycopg2-binary, sqlalchemy

# Machine Learning
scikit-learn, xgboost, lightgbm, catboost

# Interpretabilidade
shap

# Balanceamento
imbalanced-learn

# Utilit√°rios
joblib (salvar modelos), python-dotenv (env vars)
```

---

## Estrutura de Diret√≥rios Proposta

```
oscar_movie_database/
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ raw/                    # Dados brutos exportados
‚îÇ   ‚îú‚îÄ‚îÄ processed/              # Dados processados
‚îÇ   ‚îî‚îÄ‚îÄ predictions/            # Predi√ß√µes finais
‚îú‚îÄ‚îÄ notebooks/
‚îÇ   ‚îú‚îÄ‚îÄ 01_eda.ipynb           # An√°lise explorat√≥ria
‚îÇ   ‚îú‚îÄ‚îÄ 02_feature_engineering.ipynb
‚îÇ   ‚îú‚îÄ‚îÄ 03_data_preparation.ipynb
‚îÇ   ‚îú‚îÄ‚îÄ 04_modeling.ipynb
‚îÇ   ‚îú‚îÄ‚îÄ 05_evaluation.ipynb
‚îÇ   ‚îî‚îÄ‚îÄ 06_predictions_2025.ipynb
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ data_loader.py         # Fun√ß√µes de carregamento
‚îÇ   ‚îú‚îÄ‚îÄ feature_engineering.py # Cria√ß√£o de features
‚îÇ   ‚îú‚îÄ‚îÄ preprocessing.py       # Pipelines de pr√©-processamento
‚îÇ   ‚îî‚îÄ‚îÄ utils.py               # Utilit√°rios
‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îî‚îÄ‚îÄ trained_models/        # Modelos salvos (.joblib)
‚îú‚îÄ‚îÄ reports/
‚îÇ   ‚îú‚îÄ‚îÄ figures/               # Gr√°ficos e visualiza√ß√µes
‚îÇ   ‚îî‚îÄ‚îÄ predictions_2025.csv   # Predi√ß√µes finais
‚îú‚îÄ‚îÄ requirements.txt
‚îú‚îÄ‚îÄ README.md
‚îî‚îÄ‚îÄ (arquivos existentes: scripts SQL, populate, etc.)
```

---

## Pr√≥ximos Passos Imediatos

Vamos come√ßar com a **Fase 1: EDA**. Os primeiros passos concretos s√£o:

1. ‚úÖ Criar estrutura de diret√≥rios
2. ‚úÖ Configurar ambiente Python (requirements.txt)
3. ‚úÖ Exportar dados do PostgreSQL
4. ‚úÖ Criar primeiro notebook de EDA
5. ‚úÖ An√°lise inicial dos dados

---

> [!IMPORTANT]
> Este plano √© iterativo! Vamos ajustar conforme descobrimos caracter√≠sticas dos dados e resultados dos modelos.
