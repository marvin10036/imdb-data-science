# DB Unifier - Guia de Uso

## üì¶ Instala√ß√£o de Depend√™ncias

```bash
pip install -r requirements.txt
playwright install chromium
```

## üöÄ Como Usar

### Primeira Execu√ß√£o - Processar Todos os Filmes

```bash
python3 db_unifier.py
```

O script ir√°:

- ‚úÖ Validar o arquivo CSV
- ‚úÖ Carregar progresso anterior (se existir)
- ‚úÖ Processar apenas filmes n√£o processados
- ‚úÖ Salvar resultados a cada 10 filmes
- ‚úÖ Exibir barra de progresso visual
- ‚úÖ Gerar logs em `logs/db_unifier_TIMESTAMP.log`
- ‚úÖ Salvar resultados em `movie_scores.json`
- ‚úÖ Salvar lista de erros em `error_list.json`

### Reprocessar Filmes com Erro

```bash
# 1. Renomeie o arquivo de erros
mv error_list.json error_list_from_error_list.json

# 2. Execute em modo retry
python3 db_unifier.py --retry-errors
```

## ‚öôÔ∏è Configura√ß√µes

No topo do arquivo `db_unifier.py`:

```python
MAX_WORKERS = 16        # Threads paralelas (padr√£o: 16)
SAVE_INTERVAL = 10      # Salvar a cada N filmes (padr√£o: 10)
RETRY_ATTEMPTS = 3      # Tentativas de retry (padr√£o: 3)
RETRY_MIN_WAIT = 2      # Segundos m√≠nimos entre retries (padr√£o: 2)
RETRY_MAX_WAIT = 10     # Segundos m√°ximos entre retries (padr√£o: 10)
```

### Ajuste de Performance

**Sistema r√°pido / boa conex√£o:**

```python
MAX_WORKERS = 32        # Mais threads
SAVE_INTERVAL = 20      # Salvar menos frequentemente
```

**Sistema lento / conex√£o inst√°vel:**

```python
MAX_WORKERS = 8         # Menos threads
SAVE_INTERVAL = 5       # Salvar mais frequentemente
RETRY_ATTEMPTS = 5      # Mais tentativas
```

## üìä Arquivos Gerados

| Arquivo                             | Descri√ß√£o                          |
| ----------------------------------- | ---------------------------------- |
| `movie_scores.json`                 | Scores coletados com sucesso       |
| `error_list.json`                   | IDs que falharam ap√≥s 3 tentativas |
| `logs/db_unifier_*.log`             | Logs detalhados de execu√ß√£o        |
| `movie_scores_from_error_list.json` | Scores recuperados no retry        |

## ‚ú® Recursos Implementados

### 1. **Checkpoint/Resume**

- Interrompa o script a qualquer momento (Ctrl+C)
- Execute novamente - continua de onde parou
- Progresso salvo automaticamente

### 2. **Retry Autom√°tico**

- 3 tentativas para erros de conex√£o/timeout
- Backoff exponencial (espera crescente entre tentativas)
- Apenas erros recuper√°veis s√£o retry

### 3. **Progress Bar Visual**

```
üé¨ Processando filmes: 45%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 450/1000 [05:23<06:35, 1.39filme/s]
sucesso: 445, erros: 5, nome: The Shawshank Redemption
```

### 4. **Logging Estruturado**

```
2025-11-23 21:15:32 - INFO - ‚úì Total de filmes no CSV: 1000
2025-11-23 21:15:32 - INFO - ‚úì Filmes j√° processados: 450
2025-11-23 21:15:32 - INFO - ‚úì Filmes restantes: 550
```

### 5. **Estat√≠sticas Finais**

```
‚úì Tempo total: 0:15:42
‚úì Filmes processados: 1000
‚úì Sucessos: 985
‚úó Erros: 15
‚úì Taxa de sucesso: 98.5%
‚úì Velocidade: 1.06 filmes/segundo
```

## üîß Troubleshooting

### Erro: "Arquivo CSV n√£o encontrado"

- Verifique se `movies_catalog_oscar_and_popular_2000_2025.csv` est√° no diret√≥rio

### Erro: "Coluna 'ID IMDb' n√£o encontrada"

- Verifique o nome exato da coluna no CSV
- Altere `CSV_FILE` no script se necess√°rio

### Script muito lento

- Reduza `MAX_WORKERS` (pode estar sobrecarregando o site)
- Verifique sua conex√£o de internet
- Analise os logs para identificar gargalos

### Muitos erros de conex√£o

- Aumente `RETRY_MIN_WAIT` e `RETRY_MAX_WAIT`
- Reduza `MAX_WORKERS`
- Verifique se o Metacritic est√° bloqueando requisi√ß√µes

## üìà Melhorias de Performance

Comparado com a vers√£o original:

| M√©trica    | Antes        | Depois              | Melhoria             |
| ---------- | ------------ | ------------------- | -------------------- |
| I/O disk   | A cada filme | A cada 10 filmes    | **10x menos I/O**    |
| Threads    | 8            | 16                  | **2x paralelismo**   |
| Retry      | Nenhum       | 3 tentativas        | **Menos erros**      |
| Checkpoint | N√£o          | Sim                 | **Resume funcional** |
| Logging    | Print b√°sico | Arquivo estruturado | **Debugging f√°cil**  |

**Tempo estimado** (1000 filmes):

- Antes: ~2-4 horas
- Depois: ~20-40 minutos

## üéØ Pr√≥ximos Passos

Ap√≥s coletar todos os scores, voc√™ pode:

1. **Processar os dados estat√≠sticos:**

```python
from scores_processor import features_from_scores_map
import json

with open('movie_scores.json') as f:
    scores_by_film = json.load(f)

df_features = features_from_scores_map(scores_by_film)
print(df_features.round(3))
```

2. **Exportar para CSV:**

```python
df_features.to_csv('movie_features.csv')
```

3. **An√°lise de dados com pandas/matplotlib**
